{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an advance ChatBot with session memory using LangChain.\n",
    "\n",
    "#### Specifications:\n",
    "\n",
    "* Will be able to have a conversation.\n",
    "* Will remember the previous interactions, will have memory.\n",
    "* Will be able to have different memories for different user sessions.\n",
    "* Will be able to remember limited number of messages, limited memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid Nasty Deprecation Warnings from LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect with .env file for API key access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect with LLM model and start a conversation with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenSource llama3-70b-8192 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chatbot = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HumanMessage: The User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messageToTheChatbot = [\n",
    "    HumanMessage(content=\"My favorite color is blue\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Blue is a wonderful color! It's often associated with feelings of calmness, trust, and serenity. Did you know that blue is also one of the most popular favorite colors among people?\\n\\nWhat is it about blue that you love the most? Is it a particular shade of blue, like sky blue, navy blue, or royal blue? Or is it the way blue makes you feel?\\n\\nLet's chat more about your love for blue!\", response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 15, 'total_tokens': 105, 'completion_time': 0.257343164, 'prompt_time': 0.00332196, 'queue_time': 0.015847100000000003, 'total_time': 0.260665124}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None}, id='run-31596ac7-2d3e-487f-af04-3ab2a942e40f-0', usage_metadata={'input_tokens': 15, 'output_tokens': 90, 'total_tokens': 105})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messageToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the ChatBot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just an AI, I don't have have access to personal information about you, so I don't know what your favorite color is. Would you like to tell me?\", response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 16, 'total_tokens': 53, 'completion_time': 0.106303738, 'prompt_time': 0.003422986, 'queue_time': 0.016881442, 'total_time': 0.109726724}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-c63ee979-dcbd-4b68-b087-c5ea55a310ad-0', usage_metadata={'input_tokens': 16, 'output_tokens': 37, 'total_tokens': 53})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([HumanMessage(content=\"What is my favorite color?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add memory to our ChatBot\n",
    "\n",
    "* We will use the ChatMessageHistory package.\n",
    "* We will save the ChatBot memory in a python dictionary call chatbotMemory\n",
    "* We will define the get_session_history function to create a session_id for each conversation.\n",
    "* We will use the built-in runnable RunnableWithMessageHistory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "chatbotMemory = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chatbotMemory:\n",
    "        chatbotMemory[session_id] =ChatMessageHistory()\n",
    "    return chatbotMemory[session_id]\n",
    "\n",
    "chatbot_with_message_history = RunnableWithMessageHistory(\n",
    "    chatbot,\n",
    "    get_session_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableWithMessageHistory\n",
    "\n",
    "##### When invoking a new RunnableWithMessageHistory, we specify the corresponding chat history using a configurable parameter. Let's say we want to create a chat memory for one user session, let's call it session1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = {\"configurable\": {\"session_id\":\"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Orange is a vibrant and energetic color! It's often associated with feelings of warmth, excitement, and creativity. Do you have a particular shade of orange that you're especially fond of, or is it more of a general love for the color?\\n\\nAlso, what is it about orange that resonates with you? Is it a color that reminds you of a specific memory or experience, or do you just love the way it looks?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite color is orange\")],\n",
    "    config = session1,\n",
    ")\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember! Your favorite color is orange!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, Let's change the session_id and see what happen.\n",
    "\n",
    "* Now let's create a chat memory for another user session, let's call it session2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = {\"configurable\": {\"session_id\":\"002\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the chatbot uses this new memory for session2, it will not be able to remember anything from the previous conversation in the session1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just an AI, I don't have the ability to know personal information about you, including your favorite color. However, I can ask you to tell me what your favorite color is if you'd like to share!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my favorite color?\")],\n",
    "    config=session2,\n",
    ")\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go back to session1 and see if memory is still there or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = {\"configurable\": {\"session_id\":\"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You told me earlier that your favorite color is orange!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "responseFromChatbot.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see now, the chatbot is able to remember session1 conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
