{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple Chatbot with stored memory using LangChain\n",
    "\n",
    "* A chatbot app is a software application designed to simulate conversation with human users. It uses AI to understand what someone is saying and to respond with application answers. These apps can be used for various purposes like customer support, providing information, or entertainment. Essentially, it's like texting with a program that can answer questions and help with tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this project, we will use the LangChain legacy chain LLMChain. It works well, but LangChain displays a nasty deprecation warning. To avoid it, we will enter the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenSource llama3-70b-8192 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "chatbot = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Human Message: The user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagetotheChatbot = [\n",
    "    HumanMessage(content=\"My favorite color is Green.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call the LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Green is a wonderful color! It's a calming and natural hue that can evoke feelings of growth, harmony, and balance. Did you know that green is also associated with emotions, such as freshness, hope, and renewal?\\n\\nWhat is it about the color green that you love the most? Is it the bright, lime green, the deep, forest green, or maybe the soft, minty green?\\n\\nAlso, do you have a favorite way of incorporating green into your daily life, such as wearing green clothes, decorating with green accents, or enjoying nature and the outdoors?\", response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 16, 'total_tokens': 132, 'completion_time': 0.343677903, 'prompt_time': 0.003598524, 'queue_time': 0.015006884, 'total_time': 0.347276427}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-3e30dbd5-571f-4634-91f3-9663e66042d9-0', usage_metadata={'input_tokens': 16, 'output_tokens': 116, 'total_tokens': 132})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messagetotheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if the ChatBot remembers your favorite color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a language model, I don't have any information about you or your personal preferences, so I can't tell you what your favorite color is. However, I can ask you what your favorite color is if you'd like to share!\", response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 16, 'total_tokens': 67, 'completion_time': 0.145714286, 'prompt_time': 0.003309239, 'queue_time': 0.015810469, 'total_time': 0.149023525}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None}, id='run-b06a43c5-04c7-4ee5-bc17-d32ed5f95cc7-0', usage_metadata={'input_tokens': 16, 'output_tokens': 51, 'total_tokens': 67})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As you can see, our ChatBot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Memory to the ChatBot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    chat_memory= FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    input_variable = [\"content\", \"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chatbot,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'hello!',\n",
       " 'messages': [],\n",
       " 'text': \"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'My name is Lokesh',\n",
       " 'messages': [HumanMessage(content='hello!'),\n",
       "  AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\")],\n",
       " 'text': \"Nice to meet you, Lokesh! It's great to have you here. How's your day going so far?\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"My name is Lokesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'What is my name?',\n",
       " 'messages': [HumanMessage(content='hello!'),\n",
       "  AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\"),\n",
       "  HumanMessage(content='My name is Lokesh'),\n",
       "  AIMessage(content=\"Nice to meet you, Lokesh! It's great to have you here. How's your day going so far?\")],\n",
       " 'text': 'I remember! Your name is Lokesh.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
