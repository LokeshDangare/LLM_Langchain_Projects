{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template, Chain and Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First of all we will see using OpenAI api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "# openai_api_key = os.environ[\"OpenAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAI\n",
    "# llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts and Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for Completion Model\n",
    "\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# prompt_template = PromptTemplate.from_template(\n",
    "#     \"Tell me a {adjective} story about {topic}\"\n",
    "# )\n",
    "\n",
    "# llmModelPrompt = prompt_template.format(\n",
    "#     adjective=\"curious\",\n",
    "#     topic=\"the kennedy family\"\n",
    "# )\n",
    "\n",
    "# res = llmModel.invoke(llmModelPrompt)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for Chat Completion Model\n",
    "\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# chat_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are an {profession} expert on {topic}\"),\n",
    "#         (\"user\", \"Hello, Mr. {profession}, can you please answer the question?\"),\n",
    "#         (\"ai\", \"Sure!!\"),\n",
    "#         (\"user\", \"{user_input}\"),\n",
    "\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# messages = chat_template.format_messages(\n",
    "#     profession=\"historian\",\n",
    "#     topic=\"the kennedy family\",\n",
    "#     user_input=\"How many members of the family died tragically?\"\n",
    "# )\n",
    "\n",
    "# response = chatModel.invoke(messages)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# examples = [\n",
    "#     {\"input\": \"hi!\", \"output\": \"hola!\"},\n",
    "#     {\"input\": \"bye!\", \"output\": \"adios!\"}\n",
    "# ]\n",
    "\n",
    "# example_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"human\", \"{input}\"),\n",
    "#         (\"ai\", \"{output}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# few_shot_prompt = FewShotChatMessagePromptTemplate.from_examples(\n",
    "#     example_prompt = example_prompt,\n",
    "#     examples = examples,\n",
    "# )\n",
    "\n",
    "# final_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are an english-spanish translator.\"),\n",
    "#         few_shot_prompt,\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains\n",
    "\n",
    "##### Chains are used to execute the prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# examples = [\n",
    "#     {\"input\": \"hi!\", \"output\": \"hola!\"},\n",
    "#     {\"input\": \"bye!\", \"output\": \"adios!\"}\n",
    "# ]\n",
    "\n",
    "# example_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"human\", \"{input}\"),\n",
    "#         (\"ai\", \"{output}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "#     example_prompt = example_prompt,\n",
    "#     examples = examples,\n",
    "# )\n",
    "\n",
    "# final_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are an english-spanish translator.\"),\n",
    "#         few_shot_prompt,\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# chain = final_prompt | chatModel\n",
    "\n",
    "# res = chain.invoke({\"input\": \"How are you?\"})\n",
    "\n",
    "#print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# chatModel = ChatOpenAI(model = \"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "# json_prompt = PromptTemplate.from_template(\n",
    "#     \"Return a JSON object with 'answer' key that answers the following question: {question}\"\n",
    "# )\n",
    "\n",
    "# json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "# json_chain = json_prompt | llmModel | json_parser   # This chain contain input, llm model and output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_chain.invoke({\"question\": \"What is the biggest country?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Open Source LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='What a poignant question. The Kennedy family has indeed been marked by a series of tragic events that have taken the lives of several family members. Here\\'s a brief rundown:\\n\\n1. Joseph P. Kennedy Jr. (1915-1944): The eldest son of Joseph P. Kennedy Sr., Joseph Jr. was killed in action during World War II while on a secret mission for the U.S. Navy.\\n2. Kathleen Kennedy (1920-1948): Known as \"Kick,\" Kathleen died in a plane crash in France at the age of 28.\\n3. John F. Kennedy (1917-1963): The 35th President of the United States, John F. Kennedy was assassinated in Dallas, Texas, on November 22, 1963.\\n4. Robert F. Kennedy (1925-1968): John\\'s younger brother and Attorney General of the United States, Robert was assassinated in Los Angeles, California, on June 5, 1968, while campaigning for the Democratic presidential nomination.\\n5. David Kennedy (1955-1984): The son of Robert F. Kennedy, David died of an accidental drug overdose at the age of 28.\\n6. Michael LeMoyne Kennedy (1958-1997): Another son of Robert F. Kennedy, Michael died in a skiing accident in Aspen, Colorado, at the age of 39.\\n7. John F. Kennedy Jr. (1960-1999): The son of John F. Kennedy, John Jr. died in a plane crash off the coast of Massachusetts at the age of 38, along with his wife Carolyn Bessette Kennedy and her sister Lauren Bessette.\\n8. Kara Kennedy (1960-2011): The daughter of Edward M. Kennedy, Kara died of a heart attack at the age of 51.\\n9. Saoirse Kennedy Hill (1997-2019): The granddaughter of Robert F. Kennedy, Saoirse died of an accidental overdose at the age of 22.\\n\\nThese tragedies have indeed left a profound impact on the Kennedy family, and their legacy continues to be marked by both triumph and tragedy.' response_metadata={'token_usage': {'completion_tokens': 437, 'prompt_tokens': 60, 'total_tokens': 497, 'completion_time': 1.248571429, 'prompt_time': 0.005119421, 'queue_time': 0.0002215489999999997, 'total_time': 1.25369085}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_e897b1804a', 'finish_reason': 'stop', 'logprobs': None} id='run-8a6b8538-b14b-4b84-97db-c1a9b34bf0e1-0' usage_metadata={'input_tokens': 60, 'output_tokens': 437, 'total_tokens': 497}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}\"),\n",
    "        (\"user\", \"Hello, Mr. {profession}, can you please answer the question?\"),\n",
    "        (\"ai\", \"Sure!!\"),\n",
    "        (\"user\", \"{user_input}\"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"historian\",\n",
    "    topic=\"the kennedy family\",\n",
    "    user_input=\"How many members of the family died tragically?\"\n",
    ")\n",
    "\n",
    "response = llamaChatModel.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot Promptings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"adios!\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an english-spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains\n",
    "\n",
    "##### Chains are used to execute the prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me llamo Lokesh.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"adios!\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an english-spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | llamaChatModel\n",
    "\n",
    "res = chain.invoke({\"input\": \"My name is Lokesh\"})\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with 'answer' key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | llamaChatModel | json_parser   # This chain contain input, llm model and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': {'bestPlacesToVisit': [{'place': 'Ajitabh Caves',\n",
       "    'location': 'Aurangabad',\n",
       "    'description': 'A UNESCO World Heritage Site, these ancient Buddhist caves are a must-visit for their stunning rock-cut architecture and intricate carvings.'},\n",
       "   {'place': 'Elephanta Caves',\n",
       "    'location': 'Mumbai',\n",
       "    'description': 'Located on Elephanta Island, these caves feature ancient Hindu and Buddhist rock-cut temples, including the famous Trimurti sculpture.'},\n",
       "   {'place': 'Lonavala',\n",
       "    'location': 'Pune District',\n",
       "    'description': \"A popular hill station known for its scenic beauty, waterfalls, and trekking trails. It's a great place to relax and unwind.\"},\n",
       "   {'place': 'Tadoba National Park',\n",
       "    'location': 'Chandrapur District',\n",
       "    'description': \"One of India's largest national parks, Tadoba is home to a diverse range of wildlife, including tigers, leopards, and sloth bears.\"},\n",
       "   {'place': 'Mahabaleshwar',\n",
       "    'location': 'Satara District',\n",
       "    'description': 'A charming hill station with stunning views of the Western Ghats, Mahabaleshwar is famous for its strawberries, honey, and breathtaking sunsets.'}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chain.invoke({\"question\": \"Which are the best five places to visit Maharashtra?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
