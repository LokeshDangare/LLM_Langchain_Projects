{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable PassThrough\n",
    "\n",
    "* It does not do anything to the input data.\n",
    "* Let's see it in a very simple example: chain with just RunnablePassThrough() will output the original input without any modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lokesh'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Lokesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Lambda\n",
    "\n",
    "* To use custom function inside a LCEL chain, we need to wrap it up with Runnable Lambda.\n",
    "* Let's define a very simple function to create Russian lastnames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name: str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lokeshovich'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Lokesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Parallel\n",
    "\n",
    "* We will use RunnableParallel() for running tasks in parallel.\n",
    "* This is probably the most important and most useful Runnable from LangChain.\n",
    "* In the following chain, RunnableParallel is going to run these two tasks in parallel:\n",
    "    1. operation_a will use RunnablePassthrough.\n",
    "    2. operation_b will use RunnableLambda with a russian_lastname function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"operation_b\": RunnableLambda(russian_lastname)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'Lokesh', 'operation_b': 'Lokeshovich'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Lokesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": RunnableLambda(russian_lastname_from_dictionary),\n",
    "        \"operation_c\": RunnablePassthrough(),\n",
    "    }\n",
    ") | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s one:\\n\\nRoman Abramovich, the billionaire owner of Chelsea FC, has a rather unusual hobby - he\\'s an avid collector of frozen mammoths! Yes, you read that right. In 2012, he purchased a 39,000-year-old frozen mammoth carcass for a staggering $1.5 million at an auction in New York. The mammoth, known as \"Yuka,\" is one of the most well-preserved mammoth carcasses ever found, with skin, hair, and even its brain still intact. Abramovich\\'s fascination with mammoths is said to be driven by his interest in science and history. Who knew that a Russian oligarch and a frozen mammoth would make for an intriguing combination?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Messi\",\n",
    "    \"name\": \"Abram\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see a more advanced use of Runnable Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the context, dswithbappy is a source that focuses on providing content related to various topics such as Data Science, AI, ML, NLP, DL, CV, and Python Programming, all in English.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = FAISS.from_texts(\n",
    "    [\"dswithbappy focuses on providing content related to Data Science, AI, ML, NLP, DL, CV, Python Programming etc. in English\"], \n",
    "    embedding= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatGroq(model=\"llama3-70b-8192\")\n",
    "\n",
    "retriever_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retriever_chain.invoke(\"What is dswithbappy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate way to use the runnable parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ड्सविथबैप्पी डेटा साइंस, एआई, एमएल, एनएलपी, डीएल, सीवी, पायथन प्रोग्रामिंग आदि से संबंधित सामग्री प्रदान करने पर केंद्रित है।'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq \n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"dswithbappy focuses on providing content related to Data Science, AI, ML, NLP, DL, CV, Python Programming etc. in English\"], \n",
    "    embedding= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatGroq(model=\"llama3-70b-8192\")\n",
    "\n",
    "#Whenever you see Curly braces{} inside chain, then it will be act as RunnableParallel\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"What is dswithbappy?\", \"language\": \"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'डीसविथबप्पी हे डेटा सायन्स, एआय, एमएल, एनएलपी, डीएल, सीव्ही, पायथन प्रोग्रामिंग इत्यादी विषयांवर इंग्रजी भाषेत सामग्री पुरवठा करणारे मंच आहे.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is dswithbappy?\", \"language\": \"Marathi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Según el contexto, dswithbappy se centra en proporcionar contenido relacionado con Ciencia de Datos, IA, ML, NLP, DL, CV y programación en Python, por lo que se puede inferir que dswithbappy es un sitio web, blog o plataforma de contenido en línea que se enfoca en temas de tecnología y programación.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is dswithbappy?\", \"language\": \"Spanish\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
